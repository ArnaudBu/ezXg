% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xgez.R
\name{xg_train}
\alias{xg_train}
\title{Calibrate Model}
\usage{
xg_train(data, eta = 0.3, gamma = 0, max_depth = 6,
  colsample_bytree = 1, min_child_weight = 1, nrounds = 100,
  nthread = 2, verbose = 1, cv = 1, seed = 1, objective = "auto")
}
\arguments{
\item{data}{\strong{Object}. A data structure created by the call of the
\link[ezXg]{xg_load_data} function.}

\item{eta}{\strong{Numeric}. Eta parameter for xgboost calibration.
See \link[xgboost]{xgb.train} for more details.}

\item{gamma}{\strong{Numeric}. Gamma parameter for xgboost calibration.
See \link[xgboost]{xgb.train} for more details.}

\item{max_depth}{\strong{Numeric}. Max_depth parameter for xgboost
calibration. See \link[xgboost]{xgb.train} for more details.}

\item{colsample_bytree}{\strong{Numeric}. Colsample_bytree parameter
for xgboost calibration. See \link[xgboost]{xgb.train} for more details.}

\item{min_child_weight}{\strong{Numeric}. Min_child_weight parameter for
xgboost calibration. See \link[xgboost]{xgb.train} for more details.}

\item{nrounds}{\strong{Numeric}. Nrounds parameter for xgboost calibration.
See \link[xgboost]{xgb.train} for more details.}

\item{nthread}{\strong{Numeric}. Nthread parameter for xgboost calibration.
See \link[xgboost]{xgb.train} for more details.}

\item{verbose}{\strong{Numeric}. Verbose parameter for xgboost calibration.
See \link[xgboost]{xgb.train} for more details.}

\item{cv}{\strong{Numeric}. Number of folds in cross validation. If this
parameter is set to 1, this means that cross-validation will not be
performed.}

\item{seed}{\strong{Numeric}. Seed for computation reproducability.}

\item{objective}{\strong{Character}. Objective function for the
optimization. . Eta parameter for xgboost calibration. See
 \link[xgboost]{xgb.train} for more details. Can be set to \emph{auto}
 in order to let the function choose the better model regarding the
 output variable.}
}
\value{
A trained model with following values:
\itemize{
 \item{\strong{model}}: calibrated model as returned by the
 \link[xgboost]{xgb.train} function.
 \item{\strong{ntree}}: optimal number of tree according to the test set.
 \item{\strong{formula}}: the formula used for constructing the model matrix
 and that is applied when running the model.
 \item{\strong{template}}: an empty \code{data.table} that has saved all the
 input values and that is used to appropriately format data when using
 the prediction function.
 \item{\strong{labels}}: The possible labels for prediction when performing
 a classification task with xgboost.
 \item{\strong{na.handle}}: passed to reapply to prediction
}
In case the parameter \emph{cv} is set to anithing but 1, the function
returns a 1 line data.table with the average error on the
cross-validation.
}
\description{
\code{xg_train} trains an xgboost model in order on the data structure
generated by the \link[ezXg]{xg_load_data} function.
}
\examples{
d <- xg_load_data(system.file("extdata", "titanic.csv", package = "ezXg"),
               inputs = c("Pclass", "Sex", "Age", "SibSp",
                          "Parch", "Fare", "Embarked"),
               output = "Survived",
               train.size = 0.8)
md <- xg_train(d)

}
